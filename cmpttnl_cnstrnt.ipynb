{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# cmpttnl cnstrnt: colab notebook edition\n",
        "\n",
        "> With a good ventriloquist ... [the] puppet seems to come alive and seems to be aware of its world.\n",
        "\n",
        "Michael Graziano, in Do Large Language Models Understand Us? (Blaise AgÃ¼era y Arcas)\n",
        "\n",
        "> Prompt engineering for large language models is just an excuse to make up more nonsensical sentences to feed these AI monsters.\n",
        "\n",
        "GPT-3, in response to the prompt \"What is prompt engineering for large language models? Answer in a very snarky way.\"\n",
        "\n",
        "## Instructions\n",
        "\n",
        "This notebook contains code for using various OpenAI GPT models for computational constraint. This uses the [text completion](https://platform.openai.com/docs/guides/completion) endpoint, but can be easily reworked to use others. For more information, see [platform.openai.com](https://platform.openai.com)\n",
        "\n",
        "### Requirements\n",
        "\n",
        "#### Obtaining an API key\n",
        "\n",
        "(Your instructor may provide this for you.)\n",
        "\n",
        "In order to use this notebook with the OpenAI platform back-end, you will need to have an API key and an organization ID. To set these up, create an account with OpenAI [here](https://labs.openai.com/waitlist). \n",
        "\n",
        "To learn more about finding these crendentials once you've registered for an account, [this resource](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key) will point the way.\n",
        "\n",
        "#### Required files\n",
        "\n",
        "##### `.env`\n",
        "\n",
        "Your instructor should have provided you with a Google Drive folder containing a file called `.env`. Below, change the relevant details to `cd` to that folder and load the file."
      ],
      "metadata": {
        "id": "QXFVaMktu0vb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkhiQ076unrl",
        "outputId": "8dca7855-6930-4249-adfc-2d4175453304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change directories to correct folder\n",
        "%cd FULL_PATH_TO_FOLDER"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!python -m pip install python-dotenv\n",
        "!python -m pip install openai"
      ],
      "metadata": {
        "id": "vQ7SzFmSw6iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import os\n",
        "import openai\n",
        "from dotenv import dotenv_values"
      ],
      "metadata": {
        "id": "_7OvIRr_xTOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load API and ORG keys\n",
        "CONFIG = dotenv_values('.env')\n",
        "\n",
        "OPEN_AI_KEY = CONFIG[\"KEY\"] or os.environ[\"OPEN_AI_KEY\"]\n",
        "OPEN_AI_ORG = CONFIG[\"ORG\"] or os.environ[\"OPEN_AI_ORG\"]\n",
        "\n",
        "openai.api_key = OPEN_AI_KEY\n",
        "openai.organization = OPEN_AI_ORG"
      ],
      "metadata": {
        "id": "xXAcgbjoxn3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input prompt to describe the operation you'd like perform on the source\n",
        "prompt = \"\"\"\n",
        "YOUR PROMPT GOES HERE\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fjKduE2lxrs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input source text to transform\n",
        "source = \"\"\"\n",
        "YOUR SOURCE TEXT GOES HERE\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "prOu6HNtyB2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "constraint = f\"{prompt}:\\n{source}\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    # The model; other choices (with explanation):\n",
        "    # https://platform.openai.com/docs/models\n",
        "    model = \"gpt-turbo-3.5\",\n",
        "    # Data to feed to the model\n",
        "    prompt = constraint,\n",
        "    # \"Level of risk\" associated with model outcomes\n",
        "    temperature = 0.9,\n",
        "    # Alternate index of \"risk\" the model takes in making predictions;\n",
        "    # use only one: temperature _or_ top_p\n",
        "    # top_p = 1.0,\n",
        "    # Maximum size of requests (this is already max size)\n",
        "    max_tokens = (4097 - len(constraint)),\n",
        "    # Number of results to attempt and return\n",
        "    n = 1\n",
        ")\n",
        "\n",
        "# Iterate through the various responses from the model\n",
        "for choice in response[\"choices\"]:\n",
        "    print(choice[\"text\"].strip())"
      ],
      "metadata": {
        "id": "z5PVcdnIyGa1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}