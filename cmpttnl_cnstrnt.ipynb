{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# cmpttnl cnstrnt: colab notebook edition\n",
        "\n",
        "> With a good ventriloquist ... [the] puppet seems to come alive and seems to be aware of its world.\n",
        "\n",
        "Michael Graziano, in Do Large Language Models Understand Us? (Blaise Agüera y Arcas)\n",
        "\n",
        "> Prompt engineering for large language models is just an excuse to make up more nonsensical sentences to feed these AI monsters.\n",
        "\n",
        "GPT-3, in response to the prompt \"What is prompt engineering for large language models? Answer in a very snarky way.\"\n",
        "\n",
        "## Instructions\n",
        "\n",
        "This notebook contains code for using various OpenAI GPT models for computational constraint. This uses the [text completion](https://platform.openai.com/docs/guides/completion) endpoint, but can be easily reworked to use others. For more information, see [platform.openai.com](https://platform.openai.com)\n",
        "\n",
        "### Requirements\n",
        "\n",
        "#### Obtaining an API key\n",
        "\n",
        "(Your instructor may provide this for you.)\n",
        "\n",
        "In order to use this notebook with the OpenAI platform back-end, you will need to have an API key and an organization ID. To set these up, create an account with OpenAI [here](https://labs.openai.com/waitlist). \n",
        "\n",
        "To learn more about finding these crendentials once you've registered for an account, [this resource](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key) will point the way.\n",
        "\n",
        "#### Required files\n",
        "\n",
        "##### `.env`\n",
        "\n",
        "Your instructor should have provided you with a Google Drive folder containing a file called `.env`. Below, change the relevant details to `cd` to that folder and load the file."
      ],
      "metadata": {
        "id": "QXFVaMktu0vb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkhiQ076unrl",
        "outputId": "8dca7855-6930-4249-adfc-2d4175453304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change directories to correct folder\n",
        "%cd FULL_PATH_TO_FOLDER"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!python -m pip install python-dotenv\n",
        "!python -m pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ7SzFmSw6iw",
        "outputId": "3a715d74-608a-4bb6-f149-af556e9687e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/dist-packages (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import os\n",
        "import openai\n",
        "from dotenv import dotenv_values"
      ],
      "metadata": {
        "id": "_7OvIRr_xTOV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load API and ORG keys\n",
        "CONFIG = dotenv_values('.env')\n",
        "\n",
        "OPEN_AI_KEY = CONFIG[\"KEY\"] or os.environ[\"OPEN_AI_KEY\"]\n",
        "OPEN_AI_ORG = CONFIG[\"ORG\"] or os.environ[\"OPEN_AI_ORG\"]\n",
        "\n",
        "openai.api_key = OPEN_AI_KEY\n",
        "openai.organization = OPEN_AI_ORG"
      ],
      "metadata": {
        "id": "xXAcgbjoxn3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input prompt to describe the operation you'd like perform on the source\n",
        "prompt = \"\"\"\n",
        "YOUR PROMPT GOES HERE\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fjKduE2lxrs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input source text to transform\n",
        "source = \"\"\"\n",
        "YOUR SOURCE TEXT GOES HERE\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "prOu6HNtyB2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "constraint = f\"{prompt}:\\n{source}\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    # The model; other choices (with explanation):\n",
        "    # https://platform.openai.com/docs/models\n",
        "    model = \"gpt-turbo-3.5\",\n",
        "    # Data to feed to the model\n",
        "    prompt = constraint,\n",
        "    # \"Level of risk\" associated with model outcomes\n",
        "    temperature = 0.9,\n",
        "    # Alternate index of \"risk\" the model takes in making predictions;\n",
        "    # use only one: temperature _or_ top_p\n",
        "    # top_p = 1.0,\n",
        "    # Maximum size of requests (this is already max size)\n",
        "    max_tokens = (4097 - len(constraint)),\n",
        "    # Number of results to attempt and return\n",
        "    n = 1\n",
        ")\n",
        "\n",
        "# Iterate through the various responses from the model\n",
        "for choice in response[\"choices\"]:\n",
        "    print(choice[\"text\"].strip())"
      ],
      "metadata": {
        "id": "z5PVcdnIyGa1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}